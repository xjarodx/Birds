{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 5942\n",
    "nb_validation_samples = 5875\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jills\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jills\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5942 images belonging to 200 classes.\n",
      "train_generator\n",
      "Found 5875 images belonging to 200 classes.\n",
      "validation_generator\n",
      "WARNING:tensorflow:From C:\\Users\\jills\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "5942/5942 [==============================] - 3426s 577ms/step - loss: 4.7128 - acc: 0.0356 - val_loss: 4.1720 - val_acc: 0.0766\n",
      "Epoch 2/25\n",
      "5942/5942 [==============================] - 2737s 461ms/step - loss: 4.1526 - acc: 0.0828 - val_loss: 4.1101 - val_acc: 0.1030\n",
      "Epoch 3/25\n",
      "5942/5942 [==============================] - 2740s 461ms/step - loss: 4.0579 - acc: 0.1001 - val_loss: 4.0946 - val_acc: 0.1170\n",
      "Epoch 4/25\n",
      "5942/5942 [==============================] - 2674s 450ms/step - loss: 4.0917 - acc: 0.1047 - val_loss: 4.2313 - val_acc: 0.1201\n",
      "Epoch 5/25\n",
      "5942/5942 [==============================] - 2670s 449ms/step - loss: 4.2169 - acc: 0.0995 - val_loss: 4.1871 - val_acc: 0.1130\n",
      "Epoch 6/25\n",
      "5942/5942 [==============================] - 2673s 450ms/step - loss: 4.3043 - acc: 0.0936 - val_loss: 4.3113 - val_acc: 0.0932\n",
      "Epoch 7/25\n",
      "5942/5942 [==============================] - 2676s 450ms/step - loss: 4.3210 - acc: 0.0930 - val_loss: 4.8244 - val_acc: 0.0931\n",
      "Epoch 8/25\n",
      "5942/5942 [==============================] - 2808s 473ms/step - loss: 4.4169 - acc: 0.0875 - val_loss: 4.3723 - val_acc: 0.0846\n",
      "Epoch 9/25\n",
      "5942/5942 [==============================] - 3466s 583ms/step - loss: 4.4721 - acc: 0.0847 - val_loss: 4.5882 - val_acc: 0.0847\n",
      "Epoch 10/25\n",
      "5942/5942 [==============================] - 2680s 451ms/step - loss: 4.5642 - acc: 0.0782 - val_loss: 4.8786 - val_acc: 0.0439\n",
      "Epoch 11/25\n",
      "5942/5942 [==============================] - 2683s 451ms/step - loss: 4.6695 - acc: 0.0685 - val_loss: 4.9875 - val_acc: 0.0437\n",
      "Epoch 12/25\n",
      "5942/5942 [==============================] - 2677s 450ms/step - loss: 4.7052 - acc: 0.0642 - val_loss: 4.8425 - val_acc: 0.0818\n",
      "Epoch 13/25\n",
      "5942/5942 [==============================] - 2679s 451ms/step - loss: 4.7562 - acc: 0.0604 - val_loss: 4.8521 - val_acc: 0.0490\n",
      "Epoch 14/25\n",
      "5942/5942 [==============================] - 2677s 451ms/step - loss: 4.8765 - acc: 0.0475 - val_loss: 4.8572 - val_acc: 0.0592\n",
      "Epoch 15/25\n",
      "5942/5942 [==============================] - 2675s 450ms/step - loss: 4.9367 - acc: 0.0442 - val_loss: 5.1552 - val_acc: 0.0492\n",
      "Epoch 16/25\n",
      "5942/5942 [==============================] - 2673s 450ms/step - loss: 5.0758 - acc: 0.0359 - val_loss: 5.0468 - val_acc: 0.0241\n",
      "Epoch 17/25\n",
      "5942/5942 [==============================] - 2675s 450ms/step - loss: 5.0617 - acc: 0.0354 - val_loss: 5.0112 - val_acc: 0.0224\n",
      "Epoch 18/25\n",
      "5942/5942 [==============================] - 2677s 450ms/step - loss: 5.0128 - acc: 0.0385 - val_loss: 4.9310 - val_acc: 0.0268\n",
      "Epoch 19/25\n",
      "5942/5942 [==============================] - 2674s 450ms/step - loss: 5.0195 - acc: 0.0349 - val_loss: 4.8559 - val_acc: 0.0372\n",
      "Epoch 20/25\n",
      "5942/5942 [==============================] - 2678s 451ms/step - loss: 4.9873 - acc: 0.0381 - val_loss: 5.0920 - val_acc: 0.0221\n",
      "Epoch 21/25\n",
      "5942/5942 [==============================] - 2676s 450ms/step - loss: 4.9911 - acc: 0.0386 - val_loss: 4.9776 - val_acc: 0.0380\n",
      "Epoch 22/25\n",
      "5942/5942 [==============================] - 2673s 450ms/step - loss: 5.0214 - acc: 0.0369 - val_loss: 4.8685 - val_acc: 0.0447\n",
      "Epoch 23/25\n",
      "5942/5942 [==============================] - 2675s 450ms/step - loss: 5.1076 - acc: 0.0341 - val_loss: 5.1728 - val_acc: 0.0405\n",
      "Epoch 24/25\n",
      "5942/5942 [==============================] - 2680s 451ms/step - loss: 5.3423 - acc: 0.0079 - val_loss: 5.3160 - val_acc: 0.0051\n",
      "Epoch 25/25\n",
      "5942/5942 [==============================] - 2675s 450ms/step - loss: 5.3072 - acc: 0.0067 - val_loss: 5.2996 - val_acc: 0.0051\n",
      "fit_generator\n",
      "saved model and weights\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(\"train_generator\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(\"validation_generator\")\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)\n",
    "\n",
    "print(\"fit_generator\")\n",
    "\n",
    "model.save('birds_model2.h5')\n",
    "model.save_weights('birds_weights2.h5')\n",
    "print(\"saved model and weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree_Swallow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import pandas as pd\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "test_model = load_model('../jill/birds_model2.h5')\n",
    "img = load_img('../jill/image_to_predict.jpg',False,target_size=(img_width,img_height))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "img_id = test_model.predict_classes(x)[0]\n",
    "\n",
    "file = \"../data/classes.csv\"\n",
    "file_df = pd.read_csv(file)\n",
    "\n",
    "birdClass = file_df.loc[file_df[\"id\"] == img_id][\"name\"].unique()[0]\n",
    "\n",
    "print(birdClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
